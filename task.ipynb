{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\"CNN + BiLSTM as Encoder, Transformer as Decoder\" topology\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('dataset\\Gold Price (2013-2023).csv')\n",
    "dataset.drop(['Vol.','Change %'],axis=1,inplace= True)\n",
    "dataset['Date'] = pd.to_datetime(dataset['Date'],format = \"%m/%d/%Y\")\n",
    "dataset.sort_values(by='Date', ascending=True, inplace=True)\n",
    "dataset.reset_index(drop=True, inplace=True)\n",
    "dataset['Date'] = pd.to_datetime(dataset['Date'])\n",
    "dataset.sort_values(by='Date', ascending=True, inplace=True)\n",
    "dataset.reset_index(drop=True, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "NumCols = dataset.columns.drop(['Date'])\n",
    "dataset[NumCols] = dataset[NumCols].replace({',': ''}, regex=True)\n",
    "dataset[NumCols] = dataset[NumCols].astype('float64')\n",
    "data_array = dataset[NumCols].to_numpy()\n",
    "\n",
    "def extract_year(date_str):\n",
    "    return pd.to_datetime(date_str).yea\n",
    "\n",
    "train_data = data_array[dataset['Date'].dt.year != 2022] \n",
    "test_data = data_array[dataset['Date'].dt.year == 2022]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(245, 4)\n"
     ]
    }
   ],
   "source": [
    "timesteps= 15\n",
    "\n",
    "def create_dataset(data, lookback=1):\n",
    "    X, Y = [], []\n",
    "    for i in range(len(data) - lookback):\n",
    "        X.append(data[i:(i + lookback), :])\n",
    "        Y.append(data[i + lookback, :])\n",
    "    return np.array(X), np.array(Y)\n",
    "\n",
    "train_X, train_Y = create_dataset(train_data, timesteps)\n",
    "test_X, test_Y = create_dataset(test_data, timesteps)\n",
    "\n",
    "\n",
    "print(test_Y.shape) # samples , timesteps , features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(nn.Module):\n",
    "    def __init__(self, input_features, seq_len=15):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels=input_features, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv2 = nn.Conv1d(in_channels=64, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.lstm = nn.LSTM(input_size=64, hidden_size=64, batch_first=True, bidirectional=True)\n",
    "        self.maxpool = nn.MaxPool1d(kernel_size=2, stride=2)  # Changed kernel size for appropriate dimension reduction\n",
    "\n",
    "        pooled_output_length = seq_len // 2  # After max pooling\n",
    "        lstm_output_channels = 64 * 2  # Bidirectional LSTM doubles the output size\n",
    "        self.flattened_size = pooled_output_length * lstm_output_channels\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.dense1 = nn.Linear(self.flattened_size, 512)   \n",
    "        \n",
    "    def forward(self, x):\n",
    "    # Adjusting shape for Conv1d (batch, channels, seq_len)\n",
    "        x = x.permute(0, 2, 1)  # Now x has shape [batch_size, 4, 15] which matches the expected input shape for the Conv1d layer\n",
    "    \n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.maxpool(x)\n",
    "    \n",
    "    # Adjust shape for LSTM (batch, seq_len, features)\n",
    "    # After Conv1d and pooling, the shape is [batch_size, channels, reduced_seq_len]\n",
    "    # LSTM expects (batch, seq_len, features), so we need to permute back\n",
    "        x = x.permute(0, 2, 1)  # Assuming LSTM is configured with batch_first=True\n",
    "    \n",
    "        x, _ = self.lstm(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.relu(self.dense1(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerDecoderModule(nn.Module):\n",
    "    def __init__(self, d_model, nhead, num_decoder_layers, dim_feedforward=2048, dropout=0.1):\n",
    "        super(TransformerDecoderModule, self).__init__()\n",
    "        self.decoder_layer = nn.TransformerDecoderLayer(d_model=d_model, nhead=nhead,dim_feedforward=dim_feedforward, dropout=dropout)\n",
    "        self.transformer_decoder = nn.TransformerDecoder(self.decoder_layer, num_layers=num_decoder_layers)\n",
    "\n",
    "    def forward(self, tgt, memory=None, tgt_mask=None, memory_mask=None, tgt_key_padding_mask=None, memory_key_padding_mask=None):\n",
    "        output = self.transformer_decoder(tgt=tgt, memory=memory, tgt_mask=tgt_mask,\n",
    "                                          memory_mask=memory_mask, tgt_key_padding_mask=tgt_key_padding_mask,\n",
    "                                          memory_key_padding_mask=memory_key_padding_mask)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input src Dimension: torch.Size([2308, 15, 4])\n",
      "Output Dimension after Encoder: torch.Size([2308, 512])\n",
      "Output Dimension after Decoder: torch.Size([2308, 512])\n",
      "Final Output Dimension: torch.Size([2308, 4])\n",
      "Epoch 1, Loss: 2009982.5\n",
      "Input src Dimension: torch.Size([245, 15, 4])\n",
      "Output Dimension after Encoder: torch.Size([245, 512])\n",
      "Output Dimension after Decoder: torch.Size([245, 512])\n",
      "Final Output Dimension: torch.Size([245, 4])\n",
      "Test Loss: 3245835.25\n",
      "Input src Dimension: torch.Size([2308, 15, 4])\n",
      "Output Dimension after Encoder: torch.Size([2308, 512])\n",
      "Output Dimension after Decoder: torch.Size([2308, 512])\n",
      "Final Output Dimension: torch.Size([2308, 4])\n",
      "Epoch 2, Loss: 1996016.5\n",
      "Input src Dimension: torch.Size([245, 15, 4])\n",
      "Output Dimension after Encoder: torch.Size([245, 512])\n",
      "Output Dimension after Decoder: torch.Size([245, 512])\n",
      "Final Output Dimension: torch.Size([245, 4])\n",
      "Test Loss: 3240528.0\n",
      "Input src Dimension: torch.Size([2308, 15, 4])\n",
      "Output Dimension after Encoder: torch.Size([2308, 512])\n",
      "Output Dimension after Decoder: torch.Size([2308, 512])\n",
      "Final Output Dimension: torch.Size([2308, 4])\n",
      "Epoch 3, Loss: 1992098.875\n",
      "Input src Dimension: torch.Size([245, 15, 4])\n",
      "Output Dimension after Encoder: torch.Size([245, 512])\n",
      "Output Dimension after Decoder: torch.Size([245, 512])\n",
      "Final Output Dimension: torch.Size([245, 4])\n",
      "Test Loss: 3238710.25\n",
      "Input src Dimension: torch.Size([2308, 15, 4])\n",
      "Output Dimension after Encoder: torch.Size([2308, 512])\n",
      "Output Dimension after Decoder: torch.Size([2308, 512])\n",
      "Final Output Dimension: torch.Size([2308, 4])\n",
      "Epoch 4, Loss: 1990762.875\n",
      "Input src Dimension: torch.Size([245, 15, 4])\n",
      "Output Dimension after Encoder: torch.Size([245, 512])\n",
      "Output Dimension after Decoder: torch.Size([245, 512])\n",
      "Final Output Dimension: torch.Size([245, 4])\n",
      "Test Loss: 3237323.5\n",
      "Input src Dimension: torch.Size([2308, 15, 4])\n",
      "Output Dimension after Encoder: torch.Size([2308, 512])\n",
      "Output Dimension after Decoder: torch.Size([2308, 512])\n",
      "Final Output Dimension: torch.Size([2308, 4])\n",
      "Epoch 5, Loss: 1989737.125\n",
      "Input src Dimension: torch.Size([245, 15, 4])\n",
      "Output Dimension after Encoder: torch.Size([245, 512])\n",
      "Output Dimension after Decoder: torch.Size([245, 512])\n",
      "Final Output Dimension: torch.Size([245, 4])\n",
      "Test Loss: 3235886.25\n",
      "Input src Dimension: torch.Size([2308, 15, 4])\n",
      "Output Dimension after Encoder: torch.Size([2308, 512])\n",
      "Output Dimension after Decoder: torch.Size([2308, 512])\n",
      "Final Output Dimension: torch.Size([2308, 4])\n",
      "Epoch 6, Loss: 1988667.875\n",
      "Input src Dimension: torch.Size([245, 15, 4])\n",
      "Output Dimension after Encoder: torch.Size([245, 512])\n",
      "Output Dimension after Decoder: torch.Size([245, 512])\n",
      "Final Output Dimension: torch.Size([245, 4])\n",
      "Test Loss: 3234395.25\n",
      "Input src Dimension: torch.Size([2308, 15, 4])\n",
      "Output Dimension after Encoder: torch.Size([2308, 512])\n",
      "Output Dimension after Decoder: torch.Size([2308, 512])\n",
      "Final Output Dimension: torch.Size([2308, 4])\n",
      "Epoch 7, Loss: 1987560.0\n",
      "Input src Dimension: torch.Size([245, 15, 4])\n",
      "Output Dimension after Encoder: torch.Size([245, 512])\n",
      "Output Dimension after Decoder: torch.Size([245, 512])\n",
      "Final Output Dimension: torch.Size([245, 4])\n",
      "Test Loss: 3232892.25\n",
      "Input src Dimension: torch.Size([2308, 15, 4])\n",
      "Output Dimension after Encoder: torch.Size([2308, 512])\n",
      "Output Dimension after Decoder: torch.Size([2308, 512])\n",
      "Final Output Dimension: torch.Size([2308, 4])\n",
      "Epoch 8, Loss: 1986449.25\n",
      "Input src Dimension: torch.Size([245, 15, 4])\n",
      "Output Dimension after Encoder: torch.Size([245, 512])\n",
      "Output Dimension after Decoder: torch.Size([245, 512])\n",
      "Final Output Dimension: torch.Size([245, 4])\n",
      "Test Loss: 3231382.25\n",
      "Input src Dimension: torch.Size([2308, 15, 4])\n",
      "Output Dimension after Encoder: torch.Size([2308, 512])\n",
      "Output Dimension after Decoder: torch.Size([2308, 512])\n",
      "Final Output Dimension: torch.Size([2308, 4])\n",
      "Epoch 9, Loss: 1985323.5\n",
      "Input src Dimension: torch.Size([245, 15, 4])\n",
      "Output Dimension after Encoder: torch.Size([245, 512])\n",
      "Output Dimension after Decoder: torch.Size([245, 512])\n",
      "Final Output Dimension: torch.Size([245, 4])\n",
      "Test Loss: 3229852.5\n",
      "Input src Dimension: torch.Size([2308, 15, 4])\n",
      "Output Dimension after Encoder: torch.Size([2308, 512])\n",
      "Output Dimension after Decoder: torch.Size([2308, 512])\n",
      "Final Output Dimension: torch.Size([2308, 4])\n",
      "Epoch 10, Loss: 1984174.375\n",
      "Input src Dimension: torch.Size([245, 15, 4])\n",
      "Output Dimension after Encoder: torch.Size([245, 512])\n",
      "Output Dimension after Decoder: torch.Size([245, 512])\n",
      "Final Output Dimension: torch.Size([245, 4])\n",
      "Test Loss: 3228295.25\n"
     ]
    }
   ],
   "source": [
    "# Define a complete model integrating both the encoder and the decoder\n",
    "class CompleteModel(nn.Module):\n",
    "    def __init__(self, input_features, seq_len, d_model=512, nhead=8, num_decoder_layers=6, dim_feedforward=2048, dropout=0.1):\n",
    "        super(CompleteModel, self).__init__()\n",
    "        self.encoder = MyModel(input_features=input_features, seq_len=seq_len)\n",
    "        self.decoder = TransformerDecoderModule(d_model=d_model, nhead=nhead,\n",
    "                                                num_decoder_layers=num_decoder_layers,\n",
    "                                                dim_feedforward=dim_feedforward, dropout=dropout)\n",
    "        self.output_layer = nn.Linear(d_model, input_features)  \n",
    "        \n",
    "    def forward(self, src, tgt):\n",
    "        print(f'Input src Dimension: {src.shape}')\n",
    "        memory = self.encoder(src)\n",
    "        print(f'Output Dimension after Encoder: {memory.shape}')\n",
    "        tgt = torch.zeros_like(memory)\n",
    "        output = self.decoder(tgt, memory)\n",
    "        print(f'Output Dimension after Decoder: {output.shape}')\n",
    "        output = self.output_layer(output)\n",
    "        print(f'Final Output Dimension: {output.shape}')\n",
    "        return output\n",
    "\n",
    "# Initialize the complete model\n",
    "model = CompleteModel(input_features=4, seq_len=15)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Prepare data for PyTorch; convert numpy arrays to tensors and send to the device\n",
    "train_X_tensor = torch.tensor(train_X, dtype=torch.float).to(device)\n",
    "train_Y_tensor = torch.tensor(train_Y, dtype=torch.float).to(device)\n",
    "test_X_tensor = torch.tensor(test_X, dtype=torch.float).to(device)\n",
    "test_Y_tensor = torch.tensor(test_Y, dtype=torch.float).to(device)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "loss_function = nn.MSELoss()  # Mean Squared Error Loss for regression tasks\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "epochs = 10  # Example number of epochs\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    output = model(train_X_tensor, None)  # None for tgt since it's generated within the model\n",
    "    loss = loss_function(output, train_Y_tensor)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    print(f'Epoch {epoch+1}, Loss: {loss.item()}')\n",
    "\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        test_output = model(test_X_tensor, None)\n",
    "        test_loss = loss_function(test_output, test_Y_tensor)\n",
    "        print(f'Test Loss: {test_loss.item()}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
